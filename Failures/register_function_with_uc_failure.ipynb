{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82b5b281-89b3-4e47-8bd4-feae9d5697b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install --upgrade \"mlflow[databricks]>=3.1.0\" openai \"databricks-connect>=16.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b3962d4-8f40-4f20-a39f-165a31411223",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_experiment(\"/Users/benmackenzie3775@gmail.com/ex1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c018ad04-9ef3-49c0-8f97-ec472369071f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from openai import OpenAI\n",
    "\n",
    "# Enable automatic tracing for all OpenAI API calls\n",
    "#mlflow.openai.autolog()\n",
    "\n",
    "# Connect to a Databricks LLM via OpenAI using the same credentials as MLflow\n",
    "# Alternatively, you can use your own OpenAI credentials here\n",
    "mlflow_creds = mlflow.utils.databricks_utils.get_databricks_host_creds()\n",
    "client = OpenAI(\n",
    "    api_key=mlflow_creds.token,\n",
    "    base_url=f\"{mlflow_creds.host}/serving-endpoints\"\n",
    ")\n",
    "\n",
    "# Create a RAG app with tracing\n",
    "@mlflow.trace\n",
    "def my_chatbot(user_question: str) -> str:\n",
    "    # Retrieve relevant context\n",
    "    context = retrieve_context(user_question)\n",
    "\n",
    "    # Generate response using LLM with retrieved context\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"databricks-llama-4-maverick\",  # If using OpenAI directly, use \"gpt-4o\" or \"gpt-3.5-turbo\"\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant. Use the provided context to answer questions.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Context: {context}\\n\\nQuestion: {user_question}\"}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=150\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "@mlflow.trace(span_type=\"RETRIEVER\")\n",
    "def retrieve_context(query: str) -> str:\n",
    "    # Simulated retrieval - in production, this would search a vector database\n",
    "    if \"mlflow\" in query.lower():\n",
    "        return \"MLflow is an open-source platform for managing the end-to-end machine learning lifecycle. It provides tools for experiment tracking, model packaging, and deployment.\"\n",
    "    return \"General information about machine learning and data science.\"\n",
    "\n",
    "# Run the app to generate a trace\n",
    "response = my_chatbot(\"What is MLflow?\")\n",
    "print(f\"Response: {response}\")\n",
    "\n",
    "# Get the trace ID for the next step\n",
    "trace_id = mlflow.get_last_active_trace_id()\n",
    "print(f\"Trace ID: {trace_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2180e8fc-669c-4917-8af0-5df8ae9c9221",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.entities.assessment import AssessmentSource, AssessmentSourceType\n",
    "\n",
    "# Simulate end-user feedback from your app\n",
    "# In production, this would be triggered when a user clicks thumbs down in your UI\n",
    "mlflow.log_feedback(\n",
    "    trace_id=trace_id,\n",
    "    name=\"user_feedback\",\n",
    "    value=False,  # False for thumbs down - user is unsatisfied\n",
    "    rationale=\"Missing details about MLflow's key features like Projects and Model Registry\",\n",
    "    source=AssessmentSource(\n",
    "        source_type=AssessmentSourceType.HUMAN,\n",
    "        source_id=\"enduser_123\",  # Would be actual user ID in production\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"✅ End-user feedback recorded!\")\n",
    "\n",
    "# In a real app, you would:\n",
    "# 1. Return the trace_id with your response to the frontend\n",
    "# 2. When user clicks thumbs up/down, call your backend API\n",
    "# 3. Your backend would then call mlflow.log_feedback() with the trace_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88f80618-16da-44c3-b704-9722778d8cd5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.genai.label_schemas import create_label_schema, InputCategorical, InputText, InputTextList\n",
    "from mlflow.genai.labeling import create_labeling_session\n",
    "\n",
    "# Define what feedback to collect\n",
    "expected_facts_schema = create_label_schema(\n",
    "    name=\"expected_facts\",\n",
    "    type=\"expectation\",  #Correctness judge requires expectations type\n",
    "    title=\"What are the expected facts?\",\n",
    "    input=InputTextList(),\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "\n",
    "# Create a labeling session\n",
    "labeling_session = create_labeling_session(\n",
    "    name=\"quickstart_review\",\n",
    "    label_schemas=[expected_facts_schema.name],\n",
    ")\n",
    "\n",
    "# Add your trace to the session\n",
    "# Get the most recent trace from the current experiment\n",
    "traces = mlflow.search_traces(\n",
    "    max_results=1  # Gets the most recent trace\n",
    ")\n",
    "labeling_session.add_traces(traces)\n",
    "\n",
    "# Share with reviewers\n",
    "print(f\"✅ Trace sent for review!\")\n",
    "print(f\"Share this link with reviewers: {labeling_session.url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c89a279e-412f-48bf-983f-da7d77b6006f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "labeled_traces = mlflow.search_traces(\n",
    "    run_id=labeling_session.mlflow_run_id,  # Labeling Sessions are MLflow Runs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7603596c-4197-4f64-a8a8-f983619b9b4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "labeled_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c7195dc-e19f-4a17-8b31-08156a78c52b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.genai.datasets\n",
    "import time\n",
    "\n",
    "\n",
    "# 1. Create an evaluation dataset\n",
    "\n",
    "# Replace with a  Catalog schema where you have CREATE TABLE permission\n",
    "uc_schema = \"ml_demo.default\"\n",
    "# This table will be created in the above UC schema\n",
    "evaluation_dataset_table_name = \"databricks_agent_eval_v2\"\n",
    "\n",
    "mlflow.genai.delete_dataset(uc_table_name=f\"{uc_schema}.{evaluation_dataset_table_name}\")\n",
    "\n",
    "eval_dataset = mlflow.genai.datasets.create_evaluation_dataset(\n",
    "    uc_table_name=f\"{uc_schema}.{evaluation_dataset_table_name}\",\n",
    ")\n",
    "print(f\"Created evaluation dataset: {uc_schema}.{evaluation_dataset_table_name}\")\n",
    "\n",
    "\n",
    "eval_dataset.merge_records(labeled_traces)\n",
    "print(f\"Added {len(traces)} records to evaluation dataset\")\n",
    "\n",
    "# Preview the dataset\n",
    "df = eval_dataset.to_df()\n",
    "print(f\"\\nDataset preview:\")\n",
    "print(f\"Total records: {len(df)}\")\n",
    "print(\"\\nSample record:\")\n",
    "sample = df.iloc[0]\n",
    "print(f\"Inputs: {sample['inputs']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec29bf54-e982-46b8-8f4f-67ba9dbcd1c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "uc_schema = \"ml_demo.default\"\n",
    "# This table will be created in the above UC schema\n",
    "evaluation_dataset_table_name = \"databricks_agent_eval_v2\"\n",
    "\n",
    "eval_dataset = mlflow.genai.get_dataset(uc_table_name=f\"{uc_schema}.{evaluation_dataset_table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d32d5178-d14a-48cc-a550-0fbf305bc0c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.genai.scorers import Correctness\n",
    "\n",
    "# Evaluate your app against expert expectations\n",
    "eval_results = mlflow.genai.evaluate(\n",
    "    data=eval_dataset,\n",
    "    predict_fn=my_chatbot,  # The app we created in Step 1\n",
    "    scorers=[Correctness()]  # Compares outputs to expected_response\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "090fcb99-0f6f-4fc2-be7a-18615ffcf7cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Observations\n",
    "\n",
    "1. There is no tracability to the 'model' yet.\n",
    "2. I don't see the Expectations in the experiment UI. ** it's in the trace..not the table **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1602c5f-f899-4f3e-86bd-5c4e7430178b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile function_agent.py\n",
    "import mlflow\n",
    "from openai import OpenAI\n",
    "\n",
    "# Enable automatic tracing for all OpenAI API calls\n",
    "#mlflow.openai.autolog()\n",
    "\n",
    "# Connect to a Databricks LLM via OpenAI using the same credentials as MLflow\n",
    "# Alternatively, you can use your own OpenAI credentials here\n",
    "mlflow_creds = mlflow.utils.databricks_utils.get_databricks_host_creds()\n",
    "client = OpenAI(\n",
    "    api_key=mlflow_creds.token,\n",
    "    base_url=f\"{mlflow_creds.host}/serving-endpoints\"\n",
    ")\n",
    "\n",
    "# Create a RAG app with tracing\n",
    "@mlflow.trace\n",
    "def my_chatbot(user_question: str) -> str:\n",
    "    # Retrieve relevant context\n",
    "    context = retrieve_context(user_question)\n",
    "\n",
    "    # Generate response using LLM with retrieved context\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"databricks-llama-4-maverick\",  # If using OpenAI directly, use \"gpt-4o\" or \"gpt-3.5-turbo\"\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant. Use the provided context to answer questions.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Context: {context}\\n\\nQuestion: {user_question}\"}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=150\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "@mlflow.trace(span_type=\"RETRIEVER\")\n",
    "def retrieve_context(query: str) -> str:\n",
    "    # Simulated retrieval - in production, this would search a vector database\n",
    "    if \"mlflow\" in query.lower():\n",
    "        return \"MLflow is an open-source platform for managing the end-to-end machine learning lifecycle. It provides tools for experiment tracking, model packaging, and deployment.\"\n",
    "    return \"General information about machine learning and data science.\"\n",
    "\n",
    "mlflow.models.set_model(my_chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d78d5b46-d909-44a0-96e0-e7d65b48b691",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models.resources import DatabricksServingEndpoint\n",
    "\n",
    "resources = [DatabricksServingEndpoint(endpoint_name=\"databricks-llama-4-maverick\")]\n",
    "\n",
    "with mlflow.start_run(run_name=\"chatbot_v1\"):\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        name=\"agent\",\n",
    "        python_model=\"chatbot_v1.py\",\n",
    "        pip_requirements=[\n",
    "            \"mlflow\",\n",
    "            \"pydantic\",\n",
    "        ],\n",
    "        resources=resources,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0c21b4c-0220-472d-9be1-d9fa18976251",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Observations\n",
    "\n",
    "1. without a run name I would not be able to distinguish future models without looking at artficts.\n",
    "2. when I run the eval using this model it will track it in the traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55345c20-7ad9-49a2-844f-daf98d494936",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "loaded_model = mlflow.pyfunc.load_model(f\"runs:/d72c0c3b1b1c45e3bc20c69078d5662a/agent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c980c5ff-698e-42ec-99b0-520ee5dcd137",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def eval_fn(user_question: str) -> str:\n",
    "    return loaded_model.predict(user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06caf444-cfd9-491e-b01a-309322b6cdcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.genai.scorers import Correctness\n",
    "\n",
    "\n",
    "eval_results = mlflow.genai.evaluate(\n",
    "    data=eval_dataset.to_df(),\n",
    "    predict_fn=eval_fn,\n",
    "    scorers=[Correctness()]  # Compares outputs to expected_response\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8dc00055-9fea-4d22-83df-eabc00e5d715",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Try to register model with Unity Catalog requires a signature which ruins everything else\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8db83df-3687-4e23-b6ee-aa39c16627d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=\"runs:/d72c0c3b1b1c45e3bc20c69078d5662a/agent\",\n",
    "    name=\"ml_demo.default.agent_1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65cf30d1-6fdc-4da1-a221-14f3105fb1f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.models.resources import DatabricksServingEndpoint\n",
    "import pandas as pd\n",
    "\n",
    "# Create example input and output dataframes\n",
    "inputs = pd.DataFrame([\"What is MLflow?\"], columns=[\"user_question\"])\n",
    "outputs = pd.DataFrame([\"MLflow is an open-source platform for managing the end-to-end machine learning lifecycle. It provides tools for experiment tracking, model packaging, and deployment\"], columns=[\"answer\"])\n",
    "\n",
    "signature = infer_signature(inputs, outputs)\n",
    "\n",
    "resources = [DatabricksServingEndpoint(endpoint_name=\"databricks-llama-4-maverick\")]\n",
    "\n",
    "with mlflow.start_run(run_name=\"chatbot_v2\"):\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        name=\"agent\",\n",
    "        python_model=\"chatbot_v1.py\",\n",
    "        pip_requirements=[\n",
    "            \"mlflow\",\n",
    "            \"pydantic\",\n",
    "        ],\n",
    "        resources=resources,\n",
    "        signature=signature\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42cd0c39-3f6a-49d0-806f-38ebce12190f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "uc_registered_model_info = mlflow.register_model(logged_agent_info.model_uri, \"ml_demo.default.agent_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1185df16-0b7e-4b89-8b6e-ef8007c677e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "loaded_model=mlflow.pyfunc.load_model(logged_agent_info.model_uri)\n",
    "def eval_fn(user_question: str) -> str:\n",
    "    return loaded_model.predict(user_question)\n",
    "\n",
    "eval_results = mlflow.genai.evaluate(\n",
    "    data=eval_dataset.to_df(),\n",
    "    #data = df,\n",
    "    predict_fn=eval_fn,\n",
    "    scorers=[Correctness()]  # Compares outputs to expected_response\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5f2e498-3620-45ee-ab24-3b2a4f81e4cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "loaded_model = mlflow.pyfunc.load_model(\"ml_demo.default.agent_2\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "register_function_with_uc_failure",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
