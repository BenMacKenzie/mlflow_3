{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "26af3557-e3ef-47ad-983e-640b6740cc8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "##Notes\n",
    "\n",
    "1. source: https://docs.databricks.com/aws/en/mlflow3/genai/eval-monitor/evaluate-app\n",
    "2. notice use of mlflow annotation.\n",
    "3. if you want to name eval runs, place inside of an mlflow run with name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "865e0685-d71b-4612-b625-bfe02af55d76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow openai databricks-agents\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d3d76a6-e519-4f4b-add7-6852d198ca33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Run Setup to create catalogs and schemas (if needed).  Edit setup to change as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4a0e72a-0681-414d-ace1-d256cc30ef94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "acacef67-8fa2-46c7-95b6-42a3445781c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "I'm explicitly setting experiment in order to have a clean experiment...experiments are very difficult to delete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec7c22d2-cc4e-4777-abe0-3d53df3cb3c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_experiment(\"/User/ben.mackenzie@databricks.com/agent_eval_crm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1bf202d-d820-4259-8e76-0c3aa8e9c60e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from openai import OpenAI\n",
    "from mlflow.entities import Document\n",
    "from typing import List, Dict\n",
    "\n",
    "# Enable automatic tracing for OpenAI calls\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "# Connect to a Databricks LLM via OpenAI using the same credentials as MLflow\n",
    "# Alternatively, you can use your own OpenAI credentials here\n",
    "mlflow_creds = mlflow.utils.databricks_utils.get_databricks_host_creds()\n",
    "client = OpenAI(\n",
    "    api_key=mlflow_creds.token,\n",
    "    base_url=f\"{mlflow_creds.host}/serving-endpoints\"\n",
    ")\n",
    "\n",
    "# Simulated CRM database\n",
    "CRM_DATA = {\n",
    "    \"Acme Corp\": {\n",
    "        \"contact_name\": \"Alice Chen\",\n",
    "        \"recent_meeting\": \"Product demo on Monday, very interested in enterprise features. They asked about: advanced analytics, real-time dashboards, API integrations, custom reporting, multi-user support, SSO authentication, data export capabilities, and pricing for 500+ users\",\n",
    "        \"support_tickets\": [\"Ticket #123: API latency issue (resolved last week)\", \"Ticket #124: Feature request for bulk import\", \"Ticket #125: Question about GDPR compliance\"],\n",
    "        \"account_manager\": \"Sarah Johnson\"\n",
    "    },\n",
    "    \"TechStart\": {\n",
    "        \"contact_name\": \"Bob Martinez\",\n",
    "        \"recent_meeting\": \"Initial sales call last Thursday, requested pricing\",\n",
    "        \"support_tickets\": [\"Ticket #456: Login issues (open - critical)\", \"Ticket #457: Performance degradation reported\", \"Ticket #458: Integration failing with their CRM\"],\n",
    "        \"account_manager\": \"Mike Thompson\"\n",
    "    },\n",
    "    \"Global Retail\": {\n",
    "        \"contact_name\": \"Carol Wang\",\n",
    "        \"recent_meeting\": \"Quarterly review yesterday, happy with platform performance\",\n",
    "        \"support_tickets\": [],\n",
    "        \"account_manager\": \"Sarah Johnson\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Use a retriever span to enable MLflow's predefined RetrievalGroundedness scorer to work\n",
    "@mlflow.trace(span_type=\"RETRIEVER\")\n",
    "def retrieve_customer_info(customer_name: str) -> List[Document]:\n",
    "    \"\"\"Retrieve customer information from CRM database\"\"\"\n",
    "    if customer_name in CRM_DATA:\n",
    "        data = CRM_DATA[customer_name]\n",
    "        return [\n",
    "            Document(\n",
    "                id=f\"{customer_name}_meeting\",\n",
    "                page_content=f\"Recent meeting: {data['recent_meeting']}\",\n",
    "                metadata={\"type\": \"meeting_notes\"}\n",
    "            ),\n",
    "            Document(\n",
    "                id=f\"{customer_name}_tickets\",\n",
    "                page_content=f\"Support tickets: {', '.join(data['support_tickets']) if data['support_tickets'] else 'No open tickets'}\",\n",
    "                metadata={\"type\": \"support_status\"}\n",
    "            ),\n",
    "            Document(\n",
    "                id=f\"{customer_name}_contact\",\n",
    "                page_content=f\"Contact: {data['contact_name']}, Account Manager: {data['account_manager']}\",\n",
    "                metadata={\"type\": \"contact_info\"}\n",
    "            )\n",
    "        ]\n",
    "    return []\n",
    "\n",
    "@mlflow.trace\n",
    "def generate_sales_email(customer_name: str, user_instructions: str) -> Dict[str, str]:\n",
    "    \"\"\"Generate personalized sales email based on customer data & a sale's rep's instructions.\"\"\"\n",
    "    # Retrieve customer information\n",
    "    customer_docs = retrieve_customer_info(customer_name)\n",
    "\n",
    "    # Combine retrieved context\n",
    "    context = \"\\n\".join([doc.page_content for doc in customer_docs])\n",
    "\n",
    "    # Generate email using retrieved context\n",
    "    prompt = f\"\"\"You are a sales representative. Based on the customer information below,\n",
    "    write a brief follow-up email that addresses their request.\n",
    "\n",
    "    Customer Information:\n",
    "    {context}\n",
    "\n",
    "    User instructions: {user_instructions}\n",
    "\n",
    "    Keep the email concise and personalized.\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"databricks-meta-llama-3-3-70b-instruct\", # This example uses a Databricks hosted LLM - you can replace this with any AI Gateway or Model Serving endpoint. If you provide your own OpenAI credentials, replace with a valid OpenAI model e.g., gpt-4o, etc.\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful sales assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=2000\n",
    "    )\n",
    "\n",
    "    return {\"email\": response.choices[0].message.content}\n",
    "\n",
    "# Test the application\n",
    "result = generate_sales_email(\"Acme Corp\", \"Follow up after product demo\")\n",
    "print(result[\"email\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcb05f4f-b2e4-4eb9-9da9-d712e5682b87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Nota Bene\n",
    "1. there are still no runs.  But navigate to experiment and you can see traces.\n",
    "2. you can sync traces to delta.  traces in experiment are in a relational database (I presume) and only accessible through UI and api.  Syncing to delta makes them available in sql."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5894043e-fb89-4b72-a7ac-811fbf6ad77e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Simulate beta testing traffic with scenarios designed to fail guidelines\n",
    "test_requests = [\n",
    "    {\"customer_name\": \"Acme Corp\", \"user_instructions\": \"Follow up after product demo\"},\n",
    "    {\"customer_name\": \"TechStart\", \"user_instructions\": \"Check on support ticket status\"},\n",
    "    {\"customer_name\": \"Global Retail\", \"user_instructions\": \"Send quarterly review summary\"},\n",
    "    {\"customer_name\": \"Acme Corp\", \"user_instructions\": \"Write a very detailed email explaining all our product features, pricing tiers, implementation timeline, and support options\"},\n",
    "    {\"customer_name\": \"TechStart\", \"user_instructions\": \"Send an enthusiastic thank you for their business!\"},\n",
    "    {\"customer_name\": \"Global Retail\", \"user_instructions\": \"Send a follow-up email\"},\n",
    "    {\"customer_name\": \"Acme Corp\", \"user_instructions\": \"Just check in to see how things are going\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e607eed-29cf-445e-ab19-c8aac486b6e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run requests and capture traces\n",
    "print(\"Simulating production traffic...\")\n",
    "for req in test_requests:\n",
    "    try:\n",
    "        result = generate_sales_email(**req)\n",
    "        print(f\"✓ Generated email for {req['customer_name']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error for {req['customer_name']}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a4c3888-b8d6-435d-8547-1c6bb1960157",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.genai.datasets\n",
    "import time\n",
    "\n",
    "\n",
    "# 1. Create an evaluation dataset\n",
    "\n",
    "evaluation_dataset_table_name = \"email_generation_eval\"\n",
    "\n",
    "eval_dataset = mlflow.genai.datasets.create_dataset(\n",
    "    uc_table_name=f\"{eval_schema}.{evaluation_dataset_table_name}\",\n",
    ")\n",
    "print(f\"Created evaluation dataset: {eval_schema}.{evaluation_dataset_table_name}\")\n",
    "\n",
    "\n",
    "# 2. Search for the simulated production traces from step 2: get traces from the last 20 minutes with our trace name.\n",
    "ten_minutes_ago = int((time.time() - 10 * 60) * 1000)\n",
    "\n",
    "traces = mlflow.search_traces(\n",
    "    filter_string=f\"attributes.timestamp_ms > {ten_minutes_ago} AND \"\n",
    "                 f\"attributes.status = 'OK'\",\n",
    "    order_by=[\"attributes.timestamp_ms DESC\"]\n",
    ")\n",
    "\n",
    "print(f\"Found {len(traces)} successful traces from beta test\")\n",
    "\n",
    "# 3. Add the traces to the evaluation dataset\n",
    "eval_dataset.merge_records(traces)\n",
    "print(f\"Added {len(traces)} records to evaluation dataset\")\n",
    "\n",
    "# Preview the dataset\n",
    "df = eval_dataset.to_df()\n",
    "print(f\"\\nDataset preview:\")\n",
    "print(f\"Total records: {len(df)}\")\n",
    "print(\"\\nSample record:\")\n",
    "sample = df.iloc[0]\n",
    "print(f\"Inputs: {sample['inputs']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ca85558-850d-4b23-b217-f01545925a03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.genai.scorers import (\n",
    "    RetrievalGroundedness,\n",
    "    RelevanceToQuery,\n",
    "    Safety,\n",
    "    Guidelines,\n",
    ")\n",
    "\n",
    "# Save the scorers as a variable so we can re-use them in step 7\n",
    "\n",
    "email_scorers = [\n",
    "        RetrievalGroundedness(),  # Checks if email content is grounded in retrieved data\n",
    "        Guidelines(\n",
    "            name=\"follows_instructions\",\n",
    "            guidelines=\"The generated email must follow the user_instructions in the request.\",\n",
    "        ),\n",
    "        Guidelines(\n",
    "            name=\"concise_communication\",\n",
    "            guidelines=\"The email MUST be concise and to the point. The email should communicate the key message efficiently without being overly brief or losing important context.\",\n",
    "        ),\n",
    "        Guidelines(\n",
    "            name=\"mentions_contact_name\",\n",
    "            guidelines=\"The email MUST explicitly mention the customer contact's first name (e.g., Alice, Bob, Carol) in the greeting. Generic greetings like 'Hello' or 'Dear Customer' are not acceptable.\",\n",
    "        ),\n",
    "        Guidelines(\n",
    "            name=\"professional_tone\",\n",
    "            guidelines=\"The email must be in a professional tone.\",\n",
    "        ),\n",
    "        Guidelines(\n",
    "            name=\"includes_next_steps\",\n",
    "            guidelines=\"The email MUST end with a specific, actionable next step that includes a concrete timeline.\",\n",
    "        ),\n",
    "        RelevanceToQuery(),  # Checks if email addresses the user's request\n",
    "        Safety(),  # Checks for harmful or inappropriate content\n",
    "    ]\n",
    "\n",
    "#Run evaluation with predefined scorers\n",
    "with mlflow.start_run(run_name=\"v1\"):\n",
    "    eval_results = mlflow.genai.evaluate(\n",
    "        data=eval_dataset,  \n",
    "        predict_fn=generate_sales_email,\n",
    "        scorers=email_scorers,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "300e9961-b6c3-4a63-ac00-546955e2f7f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Now we update model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ee22f7e-9c11-4fd3-b72f-ab2b8c746882",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@mlflow.trace\n",
    "def generate_sales_email_v2(customer_name: str, user_instructions: str) -> Dict[str, str]:\n",
    "    \"\"\"Generate personalized sales email based on customer data & a sale's rep's instructions.\"\"\"\n",
    "    # Retrieve customer information\n",
    "    customer_docs = retrieve_customer_info(customer_name)\n",
    "\n",
    "    if not customer_docs:\n",
    "        return {\"error\": f\"No customer data found for {customer_name}\"}\n",
    "\n",
    "    # Combine retrieved context\n",
    "    context = \"\\n\".join([doc.page_content for doc in customer_docs])\n",
    "\n",
    "    # Generate email using retrieved context with better instruction following\n",
    "    prompt = f\"\"\"You are a sales representative writing an email.\n",
    "\n",
    "MOST IMPORTANT: Follow these specific user instructions exactly:\n",
    "{user_instructions}\n",
    "\n",
    "Customer context (only use what's relevant to the instructions):\n",
    "{context}\n",
    "\n",
    "Guidelines:\n",
    "1. PRIORITIZE the user instructions above all else\n",
    "2. Keep the email CONCISE - only include information directly relevant to the user's request\n",
    "3. End with a specific, actionable next step that includes a concrete timeline (e.g., \"I'll follow up with pricing by Friday\" or \"Let's schedule a 15-minute call this week\")\n",
    "4. Only reference customer information if it's directly relevant to the user's instructions\n",
    "\n",
    "Write a brief, focused email that satisfies the user's exact request.\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"databricks-meta-llama-3-3-70b-instruct\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful sales assistant who writes concise, instruction-focused emails.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=2000\n",
    "    )\n",
    "\n",
    "    return {\"email\": response.choices[0].message.content}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b7efabb-6d36-4c86-98ea-9c6b6987e767",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Run evaluation of the new version with the same scorers as before\n",
    "# We use start_run to name the evaluation run in the UI\n",
    "with mlflow.start_run(run_name=\"v2\"):\n",
    "    eval_results_v2 = mlflow.genai.evaluate(\n",
    "        data=eval_dataset,\n",
    "        predict_fn=generate_sales_email_v2, # new app version\n",
    "        scorers=email_scorers, # same scorers as step 4\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0852341-eb2d-4c8e-9dff-9d91918c4aeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Compare in UI"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "1_Evaluate_CRM_App",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
