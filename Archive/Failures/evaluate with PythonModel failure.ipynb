{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2eb18a46-066c-41fd-b71f-73da888bf63b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install --upgrade \"mlflow[databricks]>=3.1.0\" openai \"databricks-connect>=16.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59ba385d-7d2f-426c-92ce-1139409c9714",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile rag_agent.py\n",
    "\n",
    "from openai import OpenAI\n",
    "from mlflow.pyfunc import PythonModel\n",
    "import mlflow\n",
    "\n",
    "class RAGAgent(PythonModel):\n",
    "    def __init__(self):\n",
    "        mlflow_creds = mlflow.utils.databricks_utils.get_databricks_host_creds()\n",
    "        self.client = client = OpenAI(\n",
    "            api_key=mlflow_creds.token,\n",
    "            base_url=f\"{mlflow_creds.host}/serving-endpoints\"\n",
    "        )\n",
    "    \n",
    "    def predict(self, context, model_input: list[str]) -> list[str]:\n",
    "      return [self._generate_response(question) for question in model_input]\n",
    "    @mlflow.trace\n",
    "    def _generate_response(self, user_question: str) -> str:\n",
    "        context = self._retrieve_context(user_question)\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"databricks-llama-4-maverick\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Context: {context}\\n\\nQuestion: {user_question}\"}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=150\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    @mlflow.trace\n",
    "    def _retrieve_context(self, query: str) -> str:\n",
    "        if \"mlflow\" in query.lower():\n",
    "            return \"MLflow is an open-source platform for managing ML workflows.\"\n",
    "        return \"General info about machine learning.\"\n",
    "\n",
    "\n",
    "from mlflow.models import set_model\n",
    "\n",
    "AGENT = RAGAgent()\n",
    "set_model(AGENT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fce7eff-802e-4816-b5f2-300419b9e2e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "AGENT.predict(None, [\"What is MLflow?\", \"What is machine learning?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7223149-c955-4a56-a877-7418634ed9e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "AGENT.predict(None, \"what is mlflow?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b085572-a81a-4d79-80e0-15c02b46c691",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models.resources import DatabricksServingEndpoint\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "resources = [DatabricksServingEndpoint(endpoint_name=\"databricks-llama-4-maverick\")]\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name=\"chatbot_v2\"):\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        name=\"agent\",\n",
    "        python_model=\"rag_agent.py\",\n",
    "        pip_requirements=[\n",
    "            \"mlflow\",\n",
    "            \"pydantic\",\n",
    "        ],\n",
    "        resources=resources,\n",
    "        signature=infer_signature(\n",
    "            [\"What is MLflow?\"],  # Example input (batch)\n",
    "            [\"MLflow is an open-source platform...\"]  # Example output\n",
    "        ),\n",
    "        input_example=[\"What is MLflow?\"]  # Batch-friendly example\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd44df9c-d05a-4f27-b6a7-9994db17be41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "loaded_model = mlflow.pyfunc.load_model(logged_agent_info.model_uri)\n",
    "loaded_model.predict([\"What is MLflow?\", \"What is machine learning?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19178be9-b91a-47b4-8ef9-1260199256b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri,\n",
    "    name=\"ml_demo.default.agent_x\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53cad39d-647b-419d-a5c7-556d2af2345b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "traces = mlflow.search_traces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48cd0b7b-4c56-4d58-a126-7f97daaaf487",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "378b8bf2-7a72-4bab-a88f-d56e54a59057",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.genai.datasets\n",
    "\n",
    "evaluation_dataset_table_name = \"ml_demo.default.rag\"\n",
    "\n",
    "eval_dataset = mlflow.genai.datasets.create_dataset(\n",
    "    uc_table_name=evaluation_dataset_table_name,\n",
    ")\n",
    "eval_dataset.merge_records(traces)\n",
    "\n",
    "# eval_dataset = mlflow.genai.get_dataset(evaluation_dataset_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58aa96f3-2898-4f85-b89f-c1479d617604",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "eval_dataset.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f45ecbaa-fb99-4341-9543-be246617c39c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def predict_fn(messages: list) -> dict:\n",
    "  return model.predict({\"messages\": messages})\n",
    "\n",
    "def predict(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "933f1ae0-ed7c-49d3-b180-88d27ae5adc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# def predict(self, context, model_input: list[str]) -> list[str]:\n",
    "#       return [self._generate_response(question) for question in model_input]\n",
    "\n",
    "#predict funtion expects a list, but it has to be serializable.\n",
    "\n",
    "def predict_fn(user_question: list) -> dict:\n",
    "  print(user_question)\n",
    "  return loaded_model.predict({\"model_input\": user_question})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea9550ca-5d1d-469c-968b-8d51c381434a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.genai.scorers import Correctness\n",
    "\n",
    "# Evaluate your app against expert expectations\n",
    "eval_results = mlflow.genai.evaluate(\n",
    "    data=eval_dataset,\n",
    "    predict_fn=predict_fn,  \n",
    "    scorers=[Correctness()]  # Compares outputs to expected_response\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "evaluate with PythonModel failure",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
